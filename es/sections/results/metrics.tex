\subsection{Métricas usadas}
Se han usado 6 métricas distintas para medir el rendimiento de los modelos. Además, una de esas métricas, la pérdida de Huber (ver sección \ref{huber_loss}) se ha usado como función de coste.

\subsubsection{Pérdida de Huber}

Como se explica en la Sección \ref{huber_loss}, está función de pérdida no prioriza los datos atípicos sino que trata a todos los datos de forma similar. Esto es muy útil, para el problema que queremos resolver.
\newline

En el dataset que se está usando, un dato que no siga el patrón (\textit{outlier}) no significa que sea un error que se deba de tener en cuenta como puede ocurrir en otros tipos de problemas. Por ejemplo, en una estación de bicicletas justo en frente de una facultad recibe una gran demanda un jueves a las 17 mientras que el resto de jueves no ha tenido tanta demanda para dicho intervalo. Esto se debe a un acontecimiento único, por ejemplo un examen en dicha facultad para ese día. Este dato, al ser un dato válido y no un error como tal, la red no aprenderá de inmediato que los jueves habrá dicha demanda sino que harán faltas múltiples días en los que se repita para que la red comience a ajustarse a dichos datos y por eso la pérdida de Huber se adapta bien a este tipo de problema. La ecuación de la pérdida de Huber es la siguiente:

\begin{equation}
\centering
    \begin{split}
    \text{Huber} = \left\{ 
        \begin{array}{cl} 
            MSE & \text{si }|\hat{y}-y| \le \delta, \\
            MAE & \text{e.o.c.}
        \end{array}\right.
    \end{split}
\end{equation}

Para la implementación del código se ha usado la propia implementación de la librería de \textit{Keras}:

\begin{minted}{python}
from tf.losses import Huber
\end{minted}

\subsubsection{\acrshort{mae}}

El error absoluto medio (\acrshort{mae}) es una de las métricas más básicas y rápidas de calcular. Se calcula usando la media entre las diferencias entre los valores reales y los valores predichos como se puede ver a continuación:

\begin{equation}
\centering
    \begin{split}
        \text{\acrshort{mae}} = \frac{1}{n} \sum_{i=1}^n |y_i - \hat{y_i}|
    \end{split}
\end{equation}

Para hacer uso de esta ecuación en \textit{Keras}, se puede importar de la siguiente forma:


\begin{minted}{python}
from tf.metrics import MeanAbsoluteError
\end{minted}

\subsubsection{\acrshort{mse} y \acrshort{rmse}}

Estas dos métricas indican básicamente los mismo. El \acrshort{mse} es un valor que se obtiene al calcular la media entre todos los valores obtenidos al aplicar el cuadrado a la diferencia entre el valor real y el valor predicho como se puede ver a continuación:

\begin{equation}
\centering
    \begin{split}
        \text{\acrshort{mse}} = \frac{1}{n} \sum_{i=1}^n (\hat{y_i} - y_i)^2
    \end{split}
\end{equation}

Por otro lado, \acrshort{rmse} es la raíz cuadrada del \acrshort{rmse} como se puede observar a continuación:

\begin{equation}
\centering
    \begin{split}
        \text{\acrshort{rmse}} = \sqrt{\acrshort{mse}}
    \end{split}
\end{equation}

Para poder hacer cálculo de \acrshort{mse} y \acrshort{rmse} se pueden importar desde \textit{tensorflow}.

\begin{minted}{python}
from tf.losses import MeanSquaredError
from tf.metrics import RootMeanSquaredError
\end{minted}

\subsubsection{\acrshort{msle} y \acrshort{rmsle}}

Estas dos métricas se usa porque hay multitud de proyectos, entre ellos, la competición de \textit{Kaggle} (ver sección \ref{kaggle_competition}) que las usan y de esa forma poder comparar los resultados. La explicación del \acrshort{msle} se puede ver en la sección \ref{MSLE_loss}. \acrshort{rmsle} es igual que \acrshort{msle} pero aplicándole una raíz cuadrada:

\begin{equation}
\centering
    \begin{split}
        \text{\acrshort{msle}} &= \frac{1}{n} \sum_{i=1}^n \left(\log{\left(\frac{y_i + 1}{\hat{y_i} + 1}\right)}\right)^2 \\
        \text{\acrshort{rmsle}} &= \sqrt{\text{\acrshort{msle}}}
    \end{split}
\end{equation}

Para poder hacer cálculo de \acrshort{msle} se puede importar la función de \textit{Keras}. Esta función además nos sirve para poder definir la función \acrshort{rmsle} como se muestra a continuación:

\begin{minted}{python}
from tf.keras.losses import MeanSquaredLogarithmicError
def RootMeanSquaredLogarithmicError(y_true, y_pred):
    msle = MeanSquaredLogarithmicError(y_true, y_pred)
    return tf.keras.backend.sqrt(msle)
\end{minted}