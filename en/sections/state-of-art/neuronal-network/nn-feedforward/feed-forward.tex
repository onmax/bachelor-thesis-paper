\subsubsection{Forward-pass algorithm}\label{feedforward}

The forward-pass algorithm is the basic algorithm with which a neural network predicts $y$. As seen in equation \ref{eqn:feedforwardexample}, the algorithm is ultimately a combination of matrix products and activation functions. A general equation can be defined as follows:

\begin{equation}
    y = a(W^{L_l} \cdot (a(W^{L_{l-1}} \cdot ... \cdot (a(W^{L_1} \cdot x')^{L_1})) \text{ } ... \text{ } ^{L_{l-1}}))^{L_l}
    \label{eqn:feedforward}
\end{equation}

This equation is computing the forward-pass algorithm, which is summarised in the following steps:

\begin{enumerate}
\item There will be a vector $x$:
\begin{enumerate}
    \item If it is the first layer of the model, x is the die to the model as an input argument (vector x) but transposed.
    \item \acrshort{ioc} $x$ will be calculated by the previous layer (vector $y$).
\end{enumerate}
\item $x'$ is computed by entering a $1$ at the beginning of the vector.
\begin{equation}
  x' = [[1] \oplus x]^T
\end{equation}

\item $y$ is computed:
\begin{equation}
  y = a(Wx')
\end{equation}
\item If it is the last layer, the model prediction will be $y$, \acrshort{ioc} go back to step 1.b.
\end{enumerate}

The same algorithm in pseudocode:

\begin{algorithm}[H]
\caption{\textit{forward-pass} algorithm}
\SetAlgoLined
\KwResult{Vector computation $y$}
 i = 0\;
 n = Number of network layers\;
 x = Input vector\;
 y = Output vector\;
 \While{$i\neq n$}{
  \eIf{i == 0}{
   $y' = x^T$\;
   }{
   $y' = y$\;
  }
  $x' = [[1] \oplus y']$\;
  $z = W^{L_i}x'$\;
  $y = a^{L_i}(z)$\;
  $i++$\;
 }
\end{algorithm}


With this equation it is easy to see that the use of one activation function per layer is necessary. As explained in section \ref{activationfunction}, without the use of the activation functions, a set of layers can be compacted into a single layer. The mathematical demonstration is shown below, the forward-pass algorithm without activation functions:

\begin{equation}
\centering
    \begin{split}
    y = W^{L_l} \cdot W^{L_{l-1}} \cdot ... \cdot W^{1} \cdot x' &= (\prod_{l;i-=1}^{i=1} W^{L_i})x' = W'x'\\
    \text{where}~W' &= (\prod_{l;i-=1}^{i=1} W^{L_i})
  \end{split}
    \label{eqn:feedforwardnoactivation}
\end{equation}


This network collapses to a single layer whose parameters are given by the matrix of $W'$. Using the example in figure \ref{fig:basic_network51}, if it were decided not to use activation functions, the dimension of the matrix $W'$ would be $(3,1)$ which coincides with the size of the input vector($x$) and the size of the output vector($y$).

\begin{equation}
\centering
    \begin{split}
    dim(W^1&) = (3,6) \\
    dim(W^2&) = (6,5) \\
    dim(W^3&) = (5,1) \\ \\
    dim(W^1 &\cdot W^2) = (3,5)\\
    dim(W') &= dim(W^1 \cdot W^2 \cdot W^3) = (3,1)
    \end{split}
\end{equation}


Reminding the following rule for the matrix product for a matrix product $A \times B = C$:

\begin{equation}
\centering
    \begin{split}
    dim(A) &= (m, n) \\
    dim(B) &= (n, k) \\
    dim(C) &= (m, k)
    \end{split}
    \label{eqn:dimensions}
\end{equation}

\begin{itemize}
    \item The dimension of matrix $C$ is given by the number of rows of $A$ ($m$), and the number of columns of $B$ ($n$).
    \item The number of columns of $A$ ($m$) must coincide with the number of columns of $B$ ($n$), a condition that is met since we are working with fully-connected neuronal networks, all the neurons in one layer are connected to the neurons in the next layer.
\end{itemize}


Returning to equation \ref{eqn:feedforwardnoactivation} and performing the same calculation as in equation \ref{eqn:dimensions} on the desired network, the size of $y$ can be obtained and will be calculated by the model. The number of rows will indicate the number of data that have been predicted and the number of columns is the number of labels for each data.
\newline

In the network shown in figure \ref{fig:basic_network51}, it has five variables as input. As an example, this network could be used to model the following problem: Predicting the cost of a house in a given city from a set of housing data in that same city. We want to predict the price value from the following variables: number of rooms, type of house, percentage of crime, geographical coordinates and square metres. This can be represented as a table where each row is a house.
\newline


\begin{table}[H]
  \centering
  \begin{threeparttable}[t]
       \begin{tabular}{l|llrrrr}
        \toprule
        {} &   \textbf{type} & \textbf{coords} & \textbf{lc$^1$} & \textbf{m2$^2$} &  \textbf{r$^3$} & \textbf{price} \\
        \midrule
        \textbf{1} &       Den &  $(40.35717, -3.81053)$ &   $5$ &   $41$ & $2$ &  65.378 \\
        \textbf{2} &   Flat &  $(40.53125, -3.72054)$ &   $2$ &   $49$ &  $3$ & 79.519 \\
        \textbf{3} &        Duplex & $(40.45990, -3.60053)$  &   $5$ &   $59$ &  $3$ & 82.578 \\
        \textbf{4} &   Flat &  $(40.43437, -3.74870)$ &   $1$ &   $84$ &  $3$ & 99.701 \\
        \textbf{5} &   Flat &  $(40.43646, -3.84071)$ &   $3$ &  $100$ & $5$ & 130.978 \\
        \textbf{6} &         Chalet &  $(40.41922, -3.57909)$ &   $1$ &  $126$ & $6$ & 160.890 \\
        \textbf{7} &   Flat &  $(40.47372, -3.58115)$ &   $4$ &   $94$ & $4$ & 215.000 \\
        \textbf{8} &         Penthouse &  $(40.52186, -3.57051)$ &   $4$ &  $142$ & $6$ & 285.398 \\
        \textbf{9} &         Chalet &  $(40.44979, -3.68003)$ &   $3$ &  $185$ & $7$ & 340.589 \\
        \textbf{10} &       Duplex & $(40.49347, -3.67969)$ & $2$ &  $209$ & $8$ & 426.000 \\
        \bottomrule
         \end{tabular}
     \begin{tablenotes}
     \item[1] lc: Level of crime in the neighbourhood.
     \item[2] m2: square meters.
     \item[3] r: Number of rooms.
   \end{tablenotes}
    \end{threeparttable}%
\caption{Example of a dataset with dwellings.}
  \label{tab:houses}
\end{table}%



% TODO Tabla

%La predicción del valor de una vivienda se calculará a partir de cinco variables de entrada. % Por cada vivienda que se quiera estudiar, se tendrá cinco valores con los que trabajar.
